{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al7VxlS3h0SO"
      },
      "source": [
        "# Hardware For ML Class Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQeCrhHvDqMy"
      },
      "source": [
        "# Modeling Albiero\n",
        "To model Albiero, we divide the dot product kernel into several steps:\n",
        "- Input Conversion:\n",
        "    - Handles conversion from DE -> AE -> AO.\n",
        "    - Accounts for the losses/noises that occur along the way.\n",
        "- Weight Conversion:\n",
        "    - Handlers conversion from DE -> AE.\n",
        "    - Accounts for normalization to [-1, 1].\n",
        "- The Dot Product itself.\n",
        "    - Performs the AE/AO dot product.\n",
        "    - Handles the conversion from AO to AE in the PD.\n",
        "- The Output conversion.\n",
        "    - Handles conversion from AE to quantized DE.\n",
        "\n",
        "\n",
        "I don't know if this is the level of expected detail, but it's a good start to actually understand what the accelerator is doing.\n",
        "\n",
        "\n",
        "There are many things I am very unsure about.\n",
        "I have left them as `TODO(Ask)` in the code. We should ask about them in office hours.\n",
        "Feel to modify the code or add your own questions.\n",
        "\n",
        "Once we have clarified these points, we can just turn these classes into pytorch operations, and run the DNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6f9ka50Vkua"
      },
      "source": [
        "# Outline of Clarifications to Ask\n",
        "## General Questions\n",
        "1. Level of Detail:\n",
        "    - It seems impossible to capture the noise without a semi-detailed step by step computation.\n",
        "    - Is this an overkill? What's the alternative? Looks like the proposal above seems basically good to go.\n",
        "2. Parameter Values:\n",
        "    - The paper does not specify all the values (e.g., feedback resistance at the PD, or crosstalk noise in PLCU MRRs)\n",
        "        - Do you know where to find them? TBD.\n",
        "        - Or can they be derived from the provided ones (e.g., MRR crosstalk from $k^2$ and FSR)? Look below for cross-talk for specifics.\n",
        "        - Or can we assume some 'ideal' default (e.g., the feedback resistance that would allow loss-less computation). Yes we can assume the ideal to begin with.\n",
        "3. Losses:\n",
        "    - In addition to noise, there are also losses.\n",
        "    - Do we ignore them, or do we take them into account? Answer: we should ignore them and we can justify this by mentioning that the losses are predictable. If the losses are not predictable then maybe we should model them.\n",
        "4. Cross-talk?\n",
        "    - Cross talk seems input dependent, meaning that the amount of noise depends on surrounding values (meaning receptive fields that are multiplexed in the same waveguide).\n",
        "    - Should we derive cross-talk for micro-ring resonator? Answer: We should try and if not we might not do it. Cross-talk is important.\n",
        "5. Do we assume constants or make something parameterized? Yes. Do not just hard-code.\n",
        "    \n",
        "\n",
        "## Specific Questions\n",
        "### Input Conversion\n",
        "- I understand that quantized inputs are turned into voltages.\n",
        "    - With what precision? In what range? Just assume some sort of ideal if it's very much not defined from the paper (i.e. just don't model it).\n",
        "    - Like [0, 1.0]?\n",
        "- The voltage is then turned into an optical signal, after being multiplied by a 'gain' in (W/V).\n",
        "    - I can't find this value.\n",
        "    - I can assume defaults that match the output deconversion?\n",
        "- AWG (Arrayed Waveguide Grating) Crosstalk.\n",
        "    - This is given as a fixed value in the paper.\n",
        "    - Can we assume it?\n",
        "    - Isn't crosstalk input-dependent.\n",
        "\n",
        "### Weight Conversion\n",
        "- The paper expects weights to be in [-1, 1]. So I assume we have to manually scale down, then scale back up right?\n",
        "- What the weights become voltages, can we assume a perfect conversion?\n",
        "    - E.g., if the weight is $0.378934373$, the voltage can exactly match that.\n",
        "\n",
        "### Optical Dot Product\n",
        "- How to compute MRR cross-talk?\n",
        "    - We are given $k^2$ (cross-coupling factor) and FSR (free spectral range).\n",
        "    - It should input-dependent?\n",
        "- How to capture RIN (relative intensity noise)?\n",
        "    - The units we are given are decibels relative to the carrier per hertz (dBc/Hz)?\n",
        "        - The bandwidth (frequency?) is later given as 5GHz.\n",
        "- How to get the \"feedback resistance\"?\n",
        "    - Allows converting current to voltage.\n",
        "\n",
        "### Output Conversion\n",
        "- How do we map voltage back to integers.\n",
        "- Like:\n",
        "    - Can we assume some uniform mapping, from (V_min -> 0) and (V_max -> int_max).\n",
        "    - Are V_min and V_max fixed parameters, or do change input by input?\n",
        "        - I.e., does 1V always correspond to the same integer, is it relative to other voltage values in the output.\n",
        "- Same question about voltage precision.\n",
        "    - Can we assume perfect voltage precision, or is something lost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TskEih9wj_PO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import typing as t\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def dB_to_linear(dB):\n",
        "    \"\"\"\n",
        "    Convert a decibel (dB) value to a linear scale factor.\n",
        "\n",
        "    For a loss L in dB, the linear efficiency factor is:\n",
        "       factor = 10^(-L/10)\n",
        "    \"\"\"\n",
        "    return 10 ** (-dB / 10)\n",
        "\n",
        "\n",
        "\n",
        "# TODO(Ask): Some of these values are hardcoded in the paper. Do we parametrize all/some of them?\n",
        "# And some of them are missing (e.g., some waveguide lengths).\n",
        "# Or is it okay to just assume the paper's values? And ideal values for the missing ones?\n",
        "class InputConversion:\n",
        "    \"\"\"\n",
        "    InputConversion handles everything from the input tensor up to right before the optical dot product.\n",
        "    It includes:\n",
        "    - Uniform quantization in case the input tensor is not already quantized.\n",
        "    - DE to AE conversion.\n",
        "    - AE to AO conversion.\n",
        "    - AO losses and noises that occur before the optical dot product.\n",
        "        - E.g., inherent losses, AWG cross talk, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        starting_tensor,\n",
        "        quantization_bitwidth=8,\n",
        "        # Used for converting from DE to AE.\n",
        "        voltage_min=0,\n",
        "        voltage_max=255,\n",
        "        # Used for converting from AE to AO.\n",
        "        optical_gain=1, # What the voltage is multiplied by to get the optical power.\n",
        "        inherent_losses_DB: t.List[float]=[], # Losses from interconnects, etc.\n",
        "        wag_cross_talk_DB=0, # Cross talk from other channels in the WAG.\n",
        "    ):\n",
        "        self.starting_tensor = starting_tensor\n",
        "        self.quantization_bitwidth = quantization_bitwidth\n",
        "        self.max_q_val = 2**quantization_bitwidth - 1\n",
        "        self.voltage_min = voltage_min\n",
        "        self.voltage_max = voltage_max\n",
        "        self.optical_gain = optical_gain\n",
        "        # Compute inherent losses.\n",
        "        self.inherent_losses_DB = inherent_losses_DB\n",
        "        self.inherent_losses = [dB_to_linear(loss) for loss in inherent_losses_DB]\n",
        "        self.inherent_loss = 1\n",
        "        for loss in self.inherent_losses:\n",
        "            self.inherent_loss *= loss\n",
        "        self.wag_cross_talk_DB = wag_cross_talk_DB\n",
        "        self.wag_cross_talk = dB_to_linear(wag_cross_talk_DB)\n",
        "\n",
        "\n",
        "        # Compute the conversions.\n",
        "        self.quantized_tensor = self.uniform_quantization(tensor=starting_tensor)\n",
        "        self.ae_tensor = self.DE_to_AE()\n",
        "        self.ao_tensor = self.AE_to_AO()\n",
        "        self.final_optical_tensor = self.apply_conversion_losses_and_noise()\n",
        "\n",
        "\n",
        "    def uniform_quantization(self, tensor):\n",
        "        \"\"\"\n",
        "        Uniformly quantize a tensor to the specified bitwidth.\n",
        "        Assume the tensor only contains positive values (post RELU, or at intial input).\n",
        "        Assume the zero point is 0.\n",
        "        Noop if the tensor is already quantized.\n",
        "        \"\"\"\n",
        "        tensor = tensor.clamp(0, self.max_q_val)\n",
        "        return torch.round(tensor).to(torch.int)\n",
        "\n",
        "\n",
        "    def DE_to_AE(self):\n",
        "        \"\"\"\n",
        "        Convert from DE (Digital Electric) to AE (Analog Electric).\n",
        "        Linearly maps the quantized tensor to a voltage range.\n",
        "        \"\"\"\n",
        "        tensor = self.quantized_tensor.float()\n",
        "        scaled = tensor / self.max_q_val\n",
        "        return self.voltage_min + (self.voltage_max - self.voltage_min) * scaled\n",
        "\n",
        "\n",
        "    def AE_to_AO(self):\n",
        "        \"\"\"\n",
        "        Convert from AE (Analog Electric) to AO (Analog Optical).\n",
        "        \"\"\"\n",
        "        return self.ae_tensor * self.optical_gain\n",
        "\n",
        "\n",
        "\n",
        "    def apply_conversion_losses_and_noise(self):\n",
        "        \"\"\"\n",
        "        Apply the conversion losses and noise to the AO tensor.\n",
        "        This includes:\n",
        "        - Inherent losses (e.g., from interconnects, etc.)\n",
        "        - AWG cross talk (e.g., from other channels in the WAG)\n",
        "        - RIN, thermal, etc. noise.\n",
        "        \"\"\"\n",
        "        # Apply inherent loss.\n",
        "        tensor = self.ao_tensor * self.inherent_loss * self.wag_cross_talk\n",
        "        return tensor\n",
        "\n",
        "\n",
        "\n",
        "class WeightConversion:\n",
        "    \"\"\"\n",
        "    WeightConversion handles everything from the weight tensor up to right before the optical dot product.\n",
        "    It only includes:\n",
        "    - Normalization of the weight tensor to put in the [-1, 1] range.\n",
        "    - DE to AE conversion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        starting_tensor,\n",
        "    ):\n",
        "        self.starting_tensor = starting_tensor\n",
        "        self.normalized_tensor, self.normalization_scale = self.uniform_normalization()\n",
        "        self.ae_tensor = self.DE_to_AE()\n",
        "\n",
        "\n",
        "    def uniform_normalization(self):\n",
        "        \"\"\"\n",
        "        Uniformly normalize the weight tensor to the [-1, 1] range.\n",
        "        \"\"\"\n",
        "        scale = torch.max(torch.abs(self.starting_tensor))\n",
        "        tensor = self.starting_tensor / scale\n",
        "        return tensor, scale\n",
        "\n",
        "\n",
        "    def DE_to_AE(self):\n",
        "        \"\"\"\n",
        "        Convert from DE (Digital Electric) to AE (Analog Electric).\n",
        "        Linearly maps the normalized tensor to a voltage range.\n",
        "        \"\"\"\n",
        "        return self.normalized_tensor.clone()\n",
        "\n",
        "\n",
        "\n",
        "class OpticalDotProduct:\n",
        "    \"\"\"\n",
        "    OpticalDotProduct handles the actual dot product when given two tensors:\n",
        "    - The AO tensor from the InputConversion.\n",
        "    - The AE tensor from the WeightConversion.\n",
        "\n",
        "    It includes:\n",
        "    - The optical dot product itself.\n",
        "    - The sum at the PD, which does the AO to AE conversion.\n",
        "    - RELU activation.\n",
        "\n",
        "    The output is the final AE tensor.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        ao_input_tensor: torch.Tensor,\n",
        "        ae_weight_tensor: torch.Tensor,\n",
        "        # MRR\n",
        "        mrr_k2 = 0.03,\n",
        "        mrr_fsr_nm = 16.1,\n",
        "        mrr_loss_dB = 0,\n",
        "        # MZM and Y-branch\n",
        "        mzm_loss_DB = 0,\n",
        "        y_branch_loss_DB = 0,\n",
        "        # PD\n",
        "        # TODO(Ask): How is the final noise computed from these values?\n",
        "        pd_rin_DBCHZ = 0,\n",
        "        pd_GHZ = 5,\n",
        "        pd_T = 300, # Temperature in Kelvin.\n",
        "        pd_responsivity = 1.0, # In A/W.\n",
        "        pd_dark_current_pA = 0, # In pA @ 1V.\n",
        "        pd_resistance = 50, # In Ohm. TODO: Not specified anywhere in the paper.\n",
        "    ):\n",
        "        self.ao_input_tensor = ao_input_tensor\n",
        "        self.ae_weight_tensor = ae_weight_tensor\n",
        "        self.mzm_loss_DB = mzm_loss_DB\n",
        "        self.mzm_loss = dB_to_linear(mzm_loss_DB)\n",
        "        self.y_branch_loss_DB = y_branch_loss_DB\n",
        "        self.y_branch_loss = dB_to_linear(y_branch_loss_DB)\n",
        "        self.mrr_lost_dB = mrr_loss_dB\n",
        "        self.mrr_loss = dB_to_linear(mrr_loss_dB)\n",
        "        self.mrr_k2 = mrr_k2\n",
        "        self.mrr_fsr_nm = mrr_fsr_nm\n",
        "        self.pd_resistance = pd_resistance\n",
        "        self.pd_responsivity = pd_responsivity\n",
        "        self.pd_dark_current_pA = pd_dark_current_pA\n",
        "        self.pd_rin_DBCHZ = pd_rin_DBCHZ\n",
        "        self.pd_GHZ = pd_GHZ\n",
        "        self.pd_T = pd_T\n",
        "\n",
        "\n",
        "\n",
        "        # Compute\n",
        "        self.mzm_output = self.apply_mzm()\n",
        "        self.mrr_output = self.apply_mrr()\n",
        "        self.pd_output = self.sum_at_pd()\n",
        "        self.ae_output = self.relu_activation()\n",
        "\n",
        "\n",
        "    def apply_mzm(self):\n",
        "        \"\"\"\n",
        "        Apply the MZM loss to the optical tensor.\n",
        "        This includes:\n",
        "        - Element-wise multiplication of the two tensors.\n",
        "        - Y-branch loss\n",
        "        - MZM loss\n",
        "        \"\"\"\n",
        "        mzm_ouput = self.ao_input_tensor * self.ae_weight_tensor\n",
        "        return mzm_ouput * self.y_branch_loss * self.mzm_loss\n",
        "\n",
        "    def apply_mrr(self):\n",
        "        \"\"\"\n",
        "        Apply the MRR loss to the optical tensor.\n",
        "        This includes:\n",
        "        - MRR loss.\n",
        "        - MRR cross talk.\n",
        "        \"\"\"\n",
        "        mrr_output = self.mzm_output * self.mrr_loss\n",
        "        mrr_cross_talk_DB = 0 # TODO: Figure me out.\n",
        "        mrr_cross_talk = dB_to_linear(mrr_cross_talk_DB)\n",
        "        return mrr_output * mrr_cross_talk\n",
        "\n",
        "\n",
        "\n",
        "    def sum_at_pd(self):\n",
        "        \"\"\"\n",
        "        Sum the optical tensor at the PD.\n",
        "        This includes:\n",
        "        - PD responsivity.\n",
        "        - PD dark current.\n",
        "        - PD noises (RIN, thermal, shot)\n",
        "        - PD resistance.\n",
        "        \"\"\"\n",
        "        pd_output = torch.sum(self.mrr_output, dim=0)\n",
        "        pd_output = pd_output + self.pd_dark_current_pA\n",
        "        noise_DB = 0 # TODO: Figure me out.\n",
        "        noise = dB_to_linear(noise_DB)\n",
        "        pd_output = pd_output * noise\n",
        "        pd_output = pd_output * self.pd_responsivity\n",
        "        return pd_output * self.pd_resistance\n",
        "\n",
        "\n",
        "    def relu_activation(self):\n",
        "        \"\"\"\n",
        "        Apply the ReLU activation function to the PD output.\n",
        "        \"\"\"\n",
        "        return torch.relu(self.pd_output)\n",
        "\n",
        "\n",
        "class OutputConversion:\n",
        "    \"\"\"\n",
        "    OutputConversion handles everything after the optical dot product up to the final output tensor.\n",
        "    It only includes:\n",
        "    - AE to DE conversion.\n",
        "    - Quantization of the DE tensor.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        ae_tensor,\n",
        "        quantization_bitwidth,\n",
        "        voltage_min: t.Optional[int]=None,\n",
        "        voltage_max: t.Optional[int]=None,\n",
        "    ):\n",
        "        self.voltage_min = voltage_min\n",
        "        self.voltage_max = voltage_max\n",
        "        self.ae_tensor = ae_tensor\n",
        "        self.quantization_bitwidth = quantization_bitwidth\n",
        "        self.max_q_val = 2**quantization_bitwidth - 1\n",
        "        self.de_tensor = self.AE_to_DE()\n",
        "        self.final_output = self.de_tensor\n",
        "\n",
        "\n",
        "\n",
        "    def AE_to_DE(self):\n",
        "        \"\"\"\n",
        "        Convert from AE (Analog Electric) to DE (Digital Electric).\n",
        "        \"\"\"\n",
        "        voltage_min = self.voltage_min or self.ae_tensor.min()\n",
        "        voltage_max = self.voltage_max or self.ae_tensor.max()\n",
        "        if voltage_min == voltage_max:\n",
        "            return self.ae_tensor.round().clamp(0, self.max_q_val).to(torch.int)\n",
        "        quantized_min = 0\n",
        "        quantized_max = self.max_q_val\n",
        "        scale = (quantized_max - quantized_min) / (voltage_max - voltage_min)\n",
        "        tensor = (self.ae_tensor - voltage_min) * scale\n",
        "        return tensor.round().clamp(quantized_min, quantized_max).to(torch.int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
